{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## OBJECT DETECTION WITH YOLOv2"
      ],
      "metadata": {
        "id": "kmAFo78SQD9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required packages\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "T9S75zheOoGh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXRDQQwEALPa",
        "outputId": "b13660f4-aeb9-409d-e7c8-cb9008a66f96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # read class names from text file\n",
        "    with open('/content/yolov2.txt', 'r') as f:\n",
        "        classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    # generate different colors for different classes \n",
        "    COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "    # read pre-trained model and config file\n",
        "    net = cv2.dnn.readNet('/content/drive/MyDrive/yolov2.weights', '/content/yolov2.cfg')"
      ],
      "metadata": {
        "id": "39N1AlXPkT6-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to get the output layer names \n",
        "# in the architecture\n",
        "def get_output_layers(net):\n",
        "    \n",
        "    layer_names = net.getLayerNames()\n",
        "    \n",
        "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "    return output_layers\n",
        "\n",
        "# function to draw bounding box on the detected object with class name\n",
        "def draw_bounding_box(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
        "\n",
        "    label = str(classes[class_id])\n",
        "\n",
        "    color = COLORS[class_id]\n",
        "\n",
        "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
        "\n",
        "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2)\n",
        "\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "gCBEKMjFW80O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yolov2(image):\n",
        "\n",
        "    Width = image.shape[1]\n",
        "    Height = image.shape[0]\n",
        "    scale = 0.00392\n",
        "\n",
        "    # create input blob \n",
        "    blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
        "\n",
        "    # set input blob for the network\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # run inference through the network\n",
        "    # and gather predictions from output layers\n",
        "    outs = net.forward(get_output_layers(net))\n",
        "\n",
        "    # initialization\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    conf_threshold = 0.5\n",
        "    nms_threshold = 0.4\n",
        "\n",
        "    # for each detetion from each output layer \n",
        "    # get the confidence, class id, bounding box params\n",
        "    # and ignore weak detections (confidence < 0.5)\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                center_x = int(detection[0] * Width)\n",
        "                center_y = int(detection[1] * Height)\n",
        "                w = int(detection[2] * Width)\n",
        "                h = int(detection[3] * Height)\n",
        "                x = center_x - w / 2\n",
        "                y = center_y - h / 2\n",
        "                class_ids.append(class_id)\n",
        "                confidences.append(float(confidence))\n",
        "                boxes.append([x, y, w, h])\n",
        "    \n",
        "    # apply non-max suppression\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "\n",
        "    # go through the detections remaining\n",
        "    # after nms and draw bounding box\n",
        "    for i in indices:\n",
        "        box = boxes[i]\n",
        "        x = box[0]\n",
        "        y = box[1]\n",
        "        w = box[2]\n",
        "        h = box[3]\n",
        "        image=draw_bounding_box(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
        "\n",
        "    return image      \n"
      ],
      "metadata": {
        "id": "wxnq8ZibW907"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the video file using OpenCV\n",
        "cap = cv2.VideoCapture(\"/content/whatsapp-video-2023-03-19-at-001922_5WHcZuxc.mp4\")\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
      ],
      "metadata": {
        "id": "c9JvI6XCXP7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = []\n",
        "while cap.isOpened():\n",
        "    # Extract the next frame from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "    \n",
        "    f = yolov2(frame)\n",
        "    frames.append(f)\n",
        "    cv2_imshow(f)\n",
        "    \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "WF3KDizgXSQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = '/content/output.mp4'\n",
        "\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_file, fourcc, fps, (width,height))\n",
        "\n",
        "for frame in frames:\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()"
      ],
      "metadata": {
        "id": "MqdZmNtgXW_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecting with YOLOV2 & Tracking & Car Counting Using Deepsort"
      ],
      "metadata": {
        "id": "SS-5cx7JzuW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install deep-sort-realtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-kJrXQUku_4",
        "outputId": "7728ffa9-e977-4dfe-c813-e981cd38dfc4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deep-sort-realtime\n",
            "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from deep-sort-realtime) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from deep-sort-realtime) (1.10.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (from deep-sort-realtime) (4.7.0.72)\n",
            "Installing collected packages: deep-sort-realtime\n",
            "Successfully installed deep-sort-realtime-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deep_sort_realtime.deepsort_tracker import DeepSort"
      ],
      "metadata": {
        "id": "phJ0pvnqvp_V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_tracker = DeepSort(max_age=5,\n",
        "                n_init=2,\n",
        "                nms_max_overlap=1.0,\n",
        "                max_cosine_distance=0.3,\n",
        "                nn_budget=None,\n",
        "                override_track_class=None,\n",
        "                embedder=\"mobilenet\",\n",
        "                half=True,\n",
        "                bgr=True,\n",
        "                embedder_gpu=True,\n",
        "                embedder_model_name=None,\n",
        "                embedder_wts=None,\n",
        "                polygon=False,\n",
        "                today=None)"
      ],
      "metadata": {
        "id": "RG-H6_4Fk93w"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yolov2(image):\n",
        "    n_i = []\n",
        "    Width = image.shape[1]\n",
        "    Height = image.shape[0]\n",
        "    scale = 0.00392\n",
        "\n",
        "    # create input blob \n",
        "    blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
        "\n",
        "    # set input blob for the network\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # run inference through the network\n",
        "    # and gather predictions from output layers\n",
        "    outs = net.forward(get_output_layers(net))\n",
        "\n",
        "    # initialization\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    conf_threshold = 0.5\n",
        "    nms_threshold = 0.4\n",
        "\n",
        "    # for each detetion from each output layer \n",
        "    # get the confidence, class id, bounding box params\n",
        "    # and ignore weak detections (confidence < 0.5)\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5 and classes[class_id]=='car':\n",
        "                center_x = int(detection[0] * Width)\n",
        "                center_y = int(detection[1] * Height)\n",
        "                w = int(detection[2] * Width)\n",
        "                h = int(detection[3] * Height)\n",
        "                x = center_x - w / 2\n",
        "                y = center_y - h / 2\n",
        "                class_ids.append(class_id)\n",
        "                confidences.append(float(confidence))\n",
        "                boxes.append([x, y, w, h])\n",
        "    \n",
        "    # apply non-max suppression\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "\n",
        "    # go through the detections remaining\n",
        "    # after nms and draw bounding box\n",
        "    for i in indices:\n",
        "        box = boxes[i]\n",
        "        x = box[0]\n",
        "        y = box[1]\n",
        "        w = box[2]\n",
        "        h = box[3]\n",
        "        n_i.append(([round(x), round(y),round(w),round(h)],confidences[i],classes[class_id]))\n",
        "        #image=draw_bounding_box(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
        "\n",
        "    return image,n_i      \n"
      ],
      "metadata": {
        "id": "gqmybvoElnmj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the video file using OpenCV\n",
        "cap = cv2.VideoCapture(\"/content/Video3.mp4\")\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
      ],
      "metadata": {
        "id": "H9mWJYXq2bV9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = []\n",
        "car_ids = []\n",
        "while cap.isOpened():\n",
        "    # Extract the next frame from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "    \n",
        "    f,n_i = yolov2(frame)\n",
        "    tracks = object_tracker.update_tracks(n_i, frame=f)\n",
        "    \n",
        "    for track in tracks:\n",
        "      if not track.is_confirmed():\n",
        "        continue\n",
        "      track_id = track.track_id\n",
        "      ltrb = track.to_ltrb()\n",
        "        \n",
        "      bbox = ltrb\n",
        "\n",
        "      car_ids.append(track_id)\n",
        "        \n",
        "      cv2.rectangle(f,(int(bbox[0]), int(bbox[1])),(int(bbox[2]), int(bbox[3])),(0,255,255),2)\n",
        "      cv2.putText(f, \"ID:\" + str(track_id), (int(bbox[0]+33), int(bbox[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "      cv2.putText(f, 'CAR', (int(bbox[0]), int(bbox[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2)\n",
        "  \n",
        "    \n",
        "    \n",
        "    frames.append(f)\n",
        "    cv2_imshow(f)\n",
        "    \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "9az9MjJy2hQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_ids = set(car_ids)\n",
        "num_cars = len(unique_ids)\n",
        "print(\"Number of cars:{}\".format(num_cars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lvtcpMrHA0n",
        "outputId": "a4466d5e-264c-455f-a4a3-f337ffa41727"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cars:20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = '/content/vid3_yolov2_deepsort.mp4'\n",
        "\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_file, fourcc, fps, (width,height))\n",
        "\n",
        "for frame in frames:\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()"
      ],
      "metadata": {
        "id": "kAH5kqNf6g23"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OBJECT DETECTION WITH FASTER RCNN AND TRACKING & CAR COUNTING WITH DEEPSORT"
      ],
      "metadata": {
        "id": "Wwe34mmBSPi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import cv2"
      ],
      "metadata": {
        "id": "U6MKGKQWQ1IW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEfSo5gfR0fe",
        "outputId": "d9e3c4c8-025e-456a-8de0-f827a7d7d77a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coco_names = [\"person\" , \"bicycle\" , \"car\" , \"motorcycle\" , \"airplane\" , \"bus\" , \"train\" , \"truck\" , \"boat\" , \"traffic light\" , \"fire hydrant\" , \"street sign\" , \"stop sign\" , \"parking meter\" , \"bench\" , \"bird\" , \"cat\" , \"dog\" , \"horse\" , \"sheep\" , \"cow\" , \"elephant\" , \"bear\" , \"zebra\" , \"giraffe\" , \"hat\" , \"backpack\" , \"umbrella\" , \"shoe\" , \"eye glasses\" , \"handbag\" , \"tie\" , \"suitcase\" , \n",
        "\"frisbee\" , \"skis\" , \"snowboard\" , \"sports ball\" , \"kite\" , \"baseball bat\" , \n",
        "\"baseball glove\" , \"skateboard\" , \"surfboard\" , \"tennis racket\" , \"bottle\" , \n",
        "\"plate\" , \"wine glass\" , \"cup\" , \"fork\" , \"knife\" , \"spoon\" , \"bowl\" , \n",
        "\"banana\" , \"apple\" , \"sandwich\" , \"orange\" , \"broccoli\" , \"carrot\" , \"hot dog\" ,\n",
        "\"pizza\" , \"donut\" , \"cake\" , \"chair\" , \"couch\" , \"potted plant\" , \"bed\" ,\n",
        "\"mirror\" , \"dining table\" , \"window\" , \"desk\" , \"toilet\" , \"door\" , \"tv\" ,\n",
        "\"laptop\" , \"mouse\" , \"remote\" , \"keyboard\" , \"cell phone\" , \"microwave\" ,\n",
        "\"oven\" , \"toaster\" , \"sink\" , \"refrigerator\" , \"blender\" , \"book\" ,\n",
        "\"clock\" , \"vase\" , \"scissors\" , \"teddy bear\" , \"hair drier\" , \"toothbrush\" , \"hair brush\"]"
      ],
      "metadata": {
        "id": "CFe_OEWYSArh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the video file using OpenCV\n",
        "cap = cv2.VideoCapture(\"/content/Video3.mp4\")\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
      ],
      "metadata": {
        "id": "uyacW_KdXL2P"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = []\n",
        "car_ids = []\n",
        "while cap.isOpened():\n",
        "    # Extract the next frame from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "    \n",
        "    #f,n_i = yolov2(frame)\n",
        "    n_i = []\n",
        "\n",
        "    transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "    input_image = transform(frame)\n",
        "    \n",
        "      # Pass the image through the model\n",
        "    with torch.no_grad():\n",
        "        output = model([input_image])\n",
        "           # Draw the predicted bounding boxes on the image\n",
        "        boxes = output[0]['boxes']\n",
        "        labels = output[0]['labels']\n",
        "        scores = output[0]['scores']\n",
        "        \n",
        "        num = torch.argwhere(scores>0.8).shape[0]\n",
        "  \n",
        "        for i in range(num):\n",
        "          x1,y1,x2,y2 = boxes[i].numpy().astype(\"int\")\n",
        "          class_name = coco_names[labels.numpy()[i]-1]\n",
        "          if(class_name == \"car\"):\n",
        "            n_i.append(([x1,y1,x2-x1,y2-y1],scores[i],class_name))\n",
        "    \n",
        "\n",
        "    tracks = object_tracker.update_tracks(n_i, frame=frame)\n",
        "    \n",
        "    for track in tracks:\n",
        "      if not track.is_confirmed():\n",
        "        continue\n",
        "      track_id = track.track_id\n",
        "      ltrb = track.to_ltrb()\n",
        "        \n",
        "      bbox = ltrb\n",
        "\n",
        "      car_ids.append(track_id)\n",
        "        \n",
        "      cv2.rectangle(frame,(int(bbox[0]), int(bbox[1])),(int(bbox[2]), int(bbox[3])),(0,255,255),2)\n",
        "      cv2.putText(frame, \"ID:\" + str(track_id), (int(bbox[0]+33), int(bbox[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "      cv2.putText(frame, 'CAR', (int(bbox[0]), int(bbox[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2)\n",
        "  \n",
        "    \n",
        "    \n",
        "    frames.append(frame)\n",
        "    cv2_imshow(frame)\n",
        "    \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "4_wbiZvwSQWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_ids = set(car_ids)\n",
        "num_cars = len(unique_ids)\n",
        "print(\"Number of cars:{}\".format(num_cars))"
      ],
      "metadata": {
        "id": "UZMoL2eHSdhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dd31efb-ad08-4feb-c0eb-8f3ca7e582cd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of cars:13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = '/content/vid3_frcnn_deepsort.mp4'\n",
        "\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_file, fourcc, fps, (width,height))\n",
        "\n",
        "for frame in frames:\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()"
      ],
      "metadata": {
        "id": "lWnTo3_PSeIL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "37Ebk_B0XT58"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}